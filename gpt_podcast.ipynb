{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0kvq2BEmI+7NXdnh0uzCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mshumer/gpt-podcast/blob/main/gpt_podcast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gpt-podcast\n",
        "By Matt Shumer (https://twitter.com/mattshumer_)\n",
        "\n",
        "Github repo: https://github.com/mshumer/gpt-podcast\n",
        "\n",
        "Generate an fictional podcast in minutes with AI.\n",
        "\n",
        "To generate a podcast:\n",
        "1.  In the second cell, add in your OpenAI and ElevenLabs keys (make sure you have a paid ElevenLabs account).\n",
        "2. Fill in the podcast participants, topic, and number of turns in the third cell.\n",
        "3. Replace `speaker_one_clip`, `speaker_one_voice_description`, `speaker_two_clip`, `speaker_two_voice_description` with relevant YouTube videos and voice descriptions.\n",
        "3. Run all the cells! After some time, your podcast file should appear in the filesystem.\n",
        "\n",
        "This is not for commercial use -- purely for research and fun!"
      ],
      "metadata": {
        "id": "VvqCFyM9WqL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFE6HvzUTjpZ"
      },
      "outputs": [],
      "source": [
        "!pip install openai elevenlabs pydub pytube moviepy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next cell, add your OpenAI and ElevenLabs keys. You need a paid ElevenLabs account for this to work!"
      ],
      "metadata": {
        "id": "wyHKiqwmTvM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import requests\n",
        "import time\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio\n",
        "openai.api_key = \"YOUR OPENAI KEY HERE\"\n",
        "eleven_labs_api_key = \"YOUR ELEVENLABS KEY HERE\" # make sure you have a paid account!"
      ],
      "metadata": {
        "id": "oeuuPbF8Tpcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enter the names of the podcast participants here, and add a topic to discuss. Finally, choose how many turns (back-and-forth conversation changes) you want the podcast to have.\n",
        "\n",
        "(note -- for more than 12 turns, you may want to switch from `gpt-4` to `gpt-4-32k`)."
      ],
      "metadata": {
        "id": "mcqieDzdUl_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speaker_one = \"Joe Rogan\"\n",
        "speaker_two = \"Rick Sanchez, of Rick and Morty\"\n",
        "\n",
        "topic = \"Artificial Intelligence\"\n",
        "\n",
        "number_of_turns = 7"
      ],
      "metadata": {
        "id": "bJCMBhosUnJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the relevant voices."
      ],
      "metadata": {
        "id": "m8EQ9aX5T28-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace with a YouTube clip of the first speaker you want to use."
      ],
      "metadata": {
        "id": "fL8idLW8T55Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speaker_one_clip = \"https://www.youtube.com/watch?v=CM_LWxh33Z8\" # a video of speaker_one speaking\n",
        "speaker_one_voice_description = \"American male, deep voice.\""
      ],
      "metadata": {
        "id": "xfHL4zJHT3e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace with a YouTube clip of the second speaker you want to use."
      ],
      "metadata": {
        "id": "lj6e7pLCT-IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speaker_two_clip = \"https://www.youtube.com/watch?v=GKPcHInn14c\" # a video of speaker_two speaking\n",
        "speaker_two_voice_description = \"A bit gruff and raspy, often slurred due to his constant state of inebriation. His speech is punctuated with frequent burps and stammers. He speaks with a cynical and sarcastic tone, often sounding dismissive or condescending. His voice also has a certain manic energy to it, reflecting his chaotic personality.\""
      ],
      "metadata": {
        "id": "WoTLWOAvT1S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create the voices!"
      ],
      "metadata": {
        "id": "_2_qZDISUCak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import *\n",
        "import requests\n",
        "\n",
        "def download_and_trim_audio(clip_url, filename, max_size):\n",
        "    yt = YouTube(clip_url)\n",
        "    stream = yt.streams.filter(only_audio=True).first()\n",
        "    stream.download(filename=f\"{filename}.webm\")\n",
        "\n",
        "    audio = AudioFileClip(f\"{filename}.webm\")\n",
        "    audio.write_audiofile(f\"{filename}.mp3\")\n",
        "\n",
        "    file_size = os.path.getsize(f\"{filename}.mp3\") / (1024 * 1024)\n",
        "    initial_duration = audio.duration\n",
        "\n",
        "    if file_size > max_size:\n",
        "        new_duration = (max_size / file_size) * initial_duration\n",
        "        audio = audio.subclip(0, new_duration)\n",
        "        audio.write_audiofile(f\"{filename}.mp3\")\n",
        "\n",
        "        final_duration = audio.duration\n",
        "        print(f\"Initial duration: {initial_duration:.2f} seconds\")\n",
        "        print(f\"Final duration: {final_duration:.2f} seconds\")\n",
        "        print(f\"Trimmed: {initial_duration - final_duration:.2f} seconds\")\n",
        "\n",
        "def upload_to_api(filename, name, description, api_key):\n",
        "    url = \"https://api.elevenlabs.io/v1/voices/add\"\n",
        "    headers = {\n",
        "      \"Accept\": \"application/json\",\n",
        "      \"xi-api-key\": api_key,\n",
        "    }\n",
        "    data = {\n",
        "        'name': name,\n",
        "        'labels': '{\"accent\": \"American\"}',\n",
        "        'description': description,\n",
        "    }\n",
        "    files = [\n",
        "        ('files', (f\"{filename}.mp3\", open(f\"{filename}.mp3\", 'rb'), 'audio/mpeg')),\n",
        "    ]\n",
        "    response = requests.post(url, headers=headers, data=data, files=files)\n",
        "    return response.json()['voice_id']\n",
        "\n",
        "# Speaker 1\n",
        "download_and_trim_audio(speaker_one_clip, 'speaker_one', 9)\n",
        "voice_one_id = upload_to_api('speaker_one', 'Podcast Voice #1', speaker_one_voice_description, eleven_labs_api_key)\n",
        "\n",
        "# Speaker 2\n",
        "download_and_trim_audio(speaker_two_clip, 'speaker_two', 9)\n",
        "voice_two_id = upload_to_api('speaker_two', 'Podcast Voice #2', speaker_two_voice_description, eleven_labs_api_key)"
      ],
      "metadata": {
        "id": "txEGRRiQUD1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OzXnmIb3ULd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_podcast(name1, name2, name1_voice, name2_voice, topic, num_turns):\n",
        "    conversation_history = []\n",
        "    system_prompt1 = {\"role\": \"system\", \"content\": f\"You are {name1}. You are recording a podcast with {name2} about {topic}. Talk as naturally as possible -- use the language {name1} would actually use. Don't just blindly agree — debate, discuss, and have fun! Respond with one message per turn. Don't include anything other than your response.\"}\n",
        "    system_prompt2 = {\"role\": \"system\", \"content\": f\"You are {name2}. You are recording a podcast with {name1} about {topic}. Talk as naturally as possible -- use the language {name2} would actually use. Don't just blindly agree — debate, discuss, and have fun! Respond with one message per turn. Don't include anything other than your response.\"}\n",
        "\n",
        "    full_audio = None\n",
        "\n",
        "    for i in range(num_turns):  # Limit the conversation to 5 turns for each character\n",
        "        for name, system_prompt in [(name1, system_prompt1), (name2, system_prompt2)]:\n",
        "            try:\n",
        "              # Adjust the role of each speaker in the conversation history\n",
        "              adjusted_history = [{\"role\": \"assistant\" if msg[\"role\"] == name else \"user\", \"content\": msg[\"content\"]} for msg in conversation_history]\n",
        "              adjusted_history.append(system_prompt)\n",
        "              response = openai.ChatCompletion.create(\n",
        "                  model=\"gpt-4\",\n",
        "                  messages=adjusted_history,\n",
        "                  presence_penalty=.7,\n",
        "              )\n",
        "              message = response.choices[0].message['content']\n",
        "              print(f\"{name}: {message}\")\n",
        "              conversation_history.append({\"role\": name, \"content\": message})\n",
        "            except:\n",
        "              time.sleep(30)\n",
        "              # Adjust the role of each speaker in the conversation history\n",
        "              adjusted_history = [{\"role\": \"assistant\" if msg[\"role\"] == name else \"user\", \"content\": msg[\"content\"]} for msg in conversation_history]\n",
        "              adjusted_history.append(system_prompt)\n",
        "              response = openai.ChatCompletion.create(\n",
        "                  model=\"gpt-4\",\n",
        "                  messages=adjusted_history,\n",
        "                  presence_penalty=.7,\n",
        "              )\n",
        "              message = response.choices[0].message['content'].replace('*(burps)*', '').replace('*(laughs)*', '').replace('*laughs and burps*', '').replace('*belches and laughs*', '')\n",
        "              print(f\"{name}: {message}\")\n",
        "              conversation_history.append({\"role\": name, \"content\": message})\n",
        "\n",
        "            if name == name1:\n",
        "              voice = name1_voice\n",
        "            else:\n",
        "              voice = name2_voice\n",
        "\n",
        "            # Generate and save audio for the message\n",
        "            try:\n",
        "              CHUNK_SIZE = 1024\n",
        "              url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice}\"\n",
        "              headers = {\n",
        "                \"Accept\": \"audio/mpeg\",\n",
        "                \"Content-Type\": \"application/json\",\n",
        "                \"xi-api-key\": eleven_labs_api_key,\n",
        "              }\n",
        "              data = {\n",
        "                \"text\": message,\n",
        "                \"model_id\": \"eleven_monolingual_v1\",\n",
        "                \"voice_settings\": {\n",
        "                  \"stability\": 0.5,\n",
        "                  \"similarity_boost\": 0.5\n",
        "                }\n",
        "              }\n",
        "              tts_response = requests.post(url, json=data, headers=headers)\n",
        "              filename = f'{name}_turn_{i}.mp3'\n",
        "              with open(filename, 'wb') as f:\n",
        "                  for chunk in tts_response.iter_content(chunk_size=CHUNK_SIZE):\n",
        "                      if chunk:\n",
        "                          f.write(chunk)\n",
        "            except:\n",
        "              time.sleep(30)\n",
        "              CHUNK_SIZE = 1024\n",
        "              url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice}\"\n",
        "              headers = {\n",
        "                \"Accept\": \"audio/mpeg\",\n",
        "                \"Content-Type\": \"application/json\",\n",
        "                \"xi-api-key\": eleven_labs_api_key,\n",
        "              }\n",
        "              data = {\n",
        "                \"text\": message,\n",
        "                \"model_id\": \"eleven_multilingual_v2\",\n",
        "                \"voice_settings\": {\n",
        "                  \"stability\": 0.7,\n",
        "                  \"similarity_boost\": 0.75\n",
        "                }\n",
        "              }\n",
        "              tts_response = requests.post(url, json=data, headers=headers)\n",
        "              filename = f'{name}_turn_{i}.mp3'\n",
        "              with open(filename, 'wb') as f:\n",
        "                  for chunk in tts_response.iter_content(chunk_size=CHUNK_SIZE):\n",
        "                      if chunk:\n",
        "                          f.write(chunk)\n",
        "\n",
        "            time.sleep(3)  # Delay to ensure the file is written to disk\n",
        "\n",
        "            # Concatenate audio\n",
        "            pause = AudioSegment.silent(duration=100)  # 100ms pause\n",
        "            new_audio = AudioSegment.from_mp3(filename)\n",
        "            full_audio = full_audio + new_audio + pause if full_audio else new_audio\n",
        "\n",
        "        if i == num_turns - 1:  # Last turn\n",
        "          wrap_up_message = {\"role\": \"system\", \"content\": \"This is your last turn to speak, wrap it up.\"}\n",
        "          conversation_history.append(wrap_up_message)\n",
        "\n",
        "    # Export full audio\n",
        "    full_audio.export(\"podcast.mp3\", format=\"mp3\")\n",
        "\n",
        "    # Play the audio in the notebook\n",
        "    return Audio(\"podcast.mp3\")"
      ],
      "metadata": {
        "id": "hzGqarwpUL6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, run this cell to generate the podcast!"
      ],
      "metadata": {
        "id": "yB6vW11pUO5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_podcast(speaker_one, speaker_two, voice_one_id, voice_two_id, topic, number_of_turns)"
      ],
      "metadata": {
        "id": "lBdKagAHUPmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}